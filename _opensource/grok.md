---
title: Grok
homepage: https://x.ai/blog/grok-os
contribute: https://vscode.dev/github/xai-org/grok-1
image: https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRvwGLjIYF5J3EJzmKaKFjLzLnCQl5fmrwoIA&s
tags: [X]

caption:
  thumbnail: https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRvwGLjIYF5J3EJzmKaKFjLzLnCQl5fmrwoIA&s
---

Grok-1 is a 314 billion parameter Mixture-of-Experts model trained from scratch by xAI.
